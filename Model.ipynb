{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ef_zFbk_cnBv"
      },
      "source": [
        "# **DATALOADING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NVD9bILs9TGA"
      },
      "outputs": [],
      "source": [
        "\n",
        "#####################################################\n",
        "################## PACKAGES #########################\n",
        "#####################################################\n",
        "import pandas as pd\n",
        "import sys \n",
        "import base64\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from datetime import datetime, timedelta, date\n",
        "from itertools import combinations\n",
        "from numpy.linalg import norm\n",
        "import pickle\n",
        "import os\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "import altair as alt\n",
        "from altair import expr, datum\n",
        "from vega_datasets import data\n",
        "from geopy.geocoders import Nominatim\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "import torch.optim as optim\n",
        "\n",
        "from utils import *\n",
        "tqdm.pandas()\n",
        "DATA_PATH = './data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNcKVv3N-DEK",
        "outputId": "0958e7ec-7160-4657-9445-680fbe7d26f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split has already been done. Exiting...\n"
          ]
        }
      ],
      "source": [
        "split_total_images_folder(DATA_PATH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bGppIF9CcsYi"
      },
      "source": [
        "# **DATA AUGMENTATION-PREPROCESS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jIPe8Scsvy2J"
      },
      "outputs": [],
      "source": [
        "# Set the paths to the training and validation data\n",
        "train_data_dir = './data/train_images'\n",
        "valid_data_dir = './data/val_images'\n",
        "\n",
        "# Set the image size, batch size\n",
        "img_size = (64, 64)\n",
        "batch_size = 32\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(size=img_size, padding=2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_data_dir,transform=train_transform)\n",
        "valid_dataset = datasets.ImageFolder(valid_data_dir,transform=valid_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tDt5mqakd28V"
      },
      "source": [
        "# **CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the CNN model architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(128 * (img_size[0] // 8) * (img_size[1] // 8), 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.pool3(x)\n",
        "        x = x.view(-1, 128 * (img_size[0] // 8) * (img_size[1] // 8))\n",
        "        x = self.fc1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jJXldThd9xX",
        "outputId": "bb769f65-c91d-4da9-8c65-5115f25e8bca"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = CNN()\n",
        "epochs= 50\n",
        "\n",
        "# Define the loss function, optimizer, and device\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Training Loss: 0.6952 - Validation Loss: 0.6901 - Training AUC: 0.5585 - Validation AUC: 0.7101\n",
            "Epoch 2 - Training Loss: 0.6908 - Validation Loss: 0.6863 - Training AUC: 0.5619 - Validation AUC: 0.6793\n",
            "Epoch 3 - Training Loss: 0.6720 - Validation Loss: 0.6739 - Training AUC: 0.6744 - Validation AUC: 0.6685\n",
            "Epoch 4 - Training Loss: 0.6618 - Validation Loss: 0.6406 - Training AUC: 0.6937 - Validation AUC: 0.7101\n",
            "Epoch 5 - Training Loss: 0.6375 - Validation Loss: 0.7202 - Training AUC: 0.6935 - Validation AUC: 0.7058\n",
            "Epoch 6 - Training Loss: 0.6311 - Validation Loss: 0.6584 - Training AUC: 0.7369 - Validation AUC: 0.6690\n",
            "Epoch 7 - Training Loss: 0.6134 - Validation Loss: 0.6455 - Training AUC: 0.7516 - Validation AUC: 0.6766\n",
            "Epoch 8 - Training Loss: 0.5821 - Validation Loss: 0.6165 - Training AUC: 0.7554 - Validation AUC: 0.7258\n",
            "Epoch 9 - Training Loss: 0.5636 - Validation Loss: 0.5994 - Training AUC: 0.7723 - Validation AUC: 0.7458\n",
            "Epoch 10 - Training Loss: 0.5662 - Validation Loss: 0.5810 - Training AUC: 0.7662 - Validation AUC: 0.7582\n",
            "Epoch 11 - Training Loss: 0.5225 - Validation Loss: 0.6978 - Training AUC: 0.8262 - Validation AUC: 0.7561\n",
            "Epoch 12 - Training Loss: 0.6663 - Validation Loss: 0.6316 - Training AUC: 0.6781 - Validation AUC: 0.7837\n",
            "Epoch 13 - Training Loss: 0.5496 - Validation Loss: 0.5872 - Training AUC: 0.8231 - Validation AUC: 0.7750\n",
            "Epoch 14 - Training Loss: 0.5287 - Validation Loss: 0.5788 - Training AUC: 0.8152 - Validation AUC: 0.7826\n",
            "Epoch 15 - Training Loss: 0.5358 - Validation Loss: 0.5543 - Training AUC: 0.7964 - Validation AUC: 0.7907\n",
            "Epoch 16 - Training Loss: 0.4923 - Validation Loss: 0.5297 - Training AUC: 0.8391 - Validation AUC: 0.8048\n",
            "Epoch 17 - Training Loss: 0.5109 - Validation Loss: 0.5581 - Training AUC: 0.8300 - Validation AUC: 0.8156\n",
            "Epoch 18 - Training Loss: 0.5436 - Validation Loss: 0.5308 - Training AUC: 0.7977 - Validation AUC: 0.8031\n",
            "Epoch 19 - Training Loss: 0.4986 - Validation Loss: 0.5265 - Training AUC: 0.8455 - Validation AUC: 0.8102\n",
            "Epoch 20 - Training Loss: 0.4569 - Validation Loss: 0.5553 - Training AUC: 0.8699 - Validation AUC: 0.8156\n",
            "Epoch 21 - Training Loss: 0.4481 - Validation Loss: 0.6574 - Training AUC: 0.8701 - Validation AUC: 0.8161\n",
            "Epoch 22 - Training Loss: 0.4149 - Validation Loss: 0.6233 - Training AUC: 0.8912 - Validation AUC: 0.8161\n",
            "Epoch 23 - Training Loss: 0.4371 - Validation Loss: 0.5167 - Training AUC: 0.8762 - Validation AUC: 0.8183\n",
            "Epoch 24 - Training Loss: 0.4202 - Validation Loss: 0.5380 - Training AUC: 0.8919 - Validation AUC: 0.8291\n",
            "Epoch 25 - Training Loss: 0.3961 - Validation Loss: 0.6275 - Training AUC: 0.8994 - Validation AUC: 0.8177\n",
            "Epoch 26 - Training Loss: 0.3572 - Validation Loss: 0.5490 - Training AUC: 0.9266 - Validation AUC: 0.8242\n",
            "Epoch 27 - Training Loss: 0.3734 - Validation Loss: 0.5278 - Training AUC: 0.9149 - Validation AUC: 0.8329\n",
            "Epoch 28 - Training Loss: 0.3321 - Validation Loss: 0.5381 - Training AUC: 0.9294 - Validation AUC: 0.8318\n",
            "Epoch 29 - Training Loss: 0.3471 - Validation Loss: 0.6092 - Training AUC: 0.9249 - Validation AUC: 0.8329\n",
            "Epoch 30 - Training Loss: 0.3327 - Validation Loss: 0.5365 - Training AUC: 0.9288 - Validation AUC: 0.8194\n",
            "Epoch 31 - Training Loss: 0.3472 - Validation Loss: 0.5048 - Training AUC: 0.9235 - Validation AUC: 0.8329\n",
            "Epoch 32 - Training Loss: 0.2855 - Validation Loss: 0.5771 - Training AUC: 0.9502 - Validation AUC: 0.8085\n",
            "Epoch 33 - Training Loss: 0.3147 - Validation Loss: 0.5560 - Training AUC: 0.9372 - Validation AUC: 0.8123\n",
            "Epoch 34 - Training Loss: 0.2926 - Validation Loss: 0.5782 - Training AUC: 0.9472 - Validation AUC: 0.8096\n",
            "Epoch 35 - Training Loss: 0.2856 - Validation Loss: 0.5440 - Training AUC: 0.9500 - Validation AUC: 0.8204\n",
            "Epoch 36 - Training Loss: 0.2656 - Validation Loss: 0.6355 - Training AUC: 0.9588 - Validation AUC: 0.8280\n",
            "Epoch 37 - Training Loss: 0.2430 - Validation Loss: 0.6600 - Training AUC: 0.9624 - Validation AUC: 0.8096\n",
            "Epoch 38 - Training Loss: 0.2894 - Validation Loss: 0.6652 - Training AUC: 0.9495 - Validation AUC: 0.8204\n",
            "Epoch 39 - Training Loss: 0.2618 - Validation Loss: 0.5659 - Training AUC: 0.9586 - Validation AUC: 0.8242\n",
            "Epoch 40 - Training Loss: 0.2881 - Validation Loss: 0.6443 - Training AUC: 0.9508 - Validation AUC: 0.8102\n",
            "Epoch 41 - Training Loss: 0.1925 - Validation Loss: 0.8390 - Training AUC: 0.9807 - Validation AUC: 0.7988\n",
            "Epoch 42 - Training Loss: 0.2460 - Validation Loss: 0.7287 - Training AUC: 0.9632 - Validation AUC: 0.8221\n",
            "Epoch 43 - Training Loss: 0.2434 - Validation Loss: 0.8366 - Training AUC: 0.9669 - Validation AUC: 0.7961\n",
            "Epoch 44 - Training Loss: 0.2248 - Validation Loss: 0.7308 - Training AUC: 0.9691 - Validation AUC: 0.8075\n",
            "Epoch 45 - Training Loss: 0.2237 - Validation Loss: 0.6836 - Training AUC: 0.9719 - Validation AUC: 0.7988\n",
            "Epoch 46 - Training Loss: 0.2067 - Validation Loss: 0.7113 - Training AUC: 0.9775 - Validation AUC: 0.8242\n",
            "Epoch 47 - Training Loss: 0.1770 - Validation Loss: 0.7600 - Training AUC: 0.9812 - Validation AUC: 0.8172\n",
            "Epoch 48 - Training Loss: 0.2021 - Validation Loss: 0.7910 - Training AUC: 0.9771 - Validation AUC: 0.8231\n",
            "Epoch 49 - Training Loss: 0.2017 - Validation Loss: 0.6717 - Training AUC: 0.9756 - Validation AUC: 0.8296\n",
            "Epoch 50 - Training Loss: 0.1726 - Validation Loss: 0.5883 - Training AUC: 0.9812 - Validation AUC: 0.8329\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "# Train the model\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    model.train()  # Set the model to training mode\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.float().unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        predicted = outputs\n",
        "        correct += (predicted == labels.float().unsqueeze(1)).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        predictions.extend(predicted.detach().cpu().numpy().flatten())\n",
        "        targets.extend(labels.detach().cpu().numpy().flatten())\n",
        "\n",
        "    # Calculate training accuracy and AUC\n",
        "    train_acc = correct / total\n",
        "    train_auc = roc_auc_score(targets, predictions)\n",
        "\n",
        "    # Validate the model\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "    valid_acc = 0.0\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in valid_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels.float().unsqueeze(1))\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            preds = outputs\n",
        "            valid_acc += torch.sum(preds == labels.float().unsqueeze(1))\n",
        "\n",
        "            predictions.extend(preds.detach().cpu().numpy().flatten())\n",
        "            targets.extend(labels.detach().cpu().numpy().flatten())\n",
        "\n",
        "    # Calculate validation AUC\n",
        "    valid_auc = roc_auc_score(targets, predictions)\n",
        "    \n",
        "    # Print the loss, accuracy, and AUC for each epoch\n",
        "    print(f'Epoch {epoch+1} - Training Loss: {running_loss/len(train_loader):.4f} - Validation Loss: {valid_loss/len(valid_loader):.4f} - Training AUC: {train_auc:.4f} - Validation AUC: {valid_auc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# predict new images\n",
        "model.eval()\n",
        "test_data_dir = './test data/images'\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "test_images = os.listdir(test_data_dir)\n",
        "results = []\n",
        "\n",
        "for image in test_images:\n",
        "    img_path = os.path.join(test_data_dir, image)\n",
        "    rel_path = os.path.relpath(img_path, './test data/')\n",
        "    rel_path =  rel_path.replace('\\\\', '/')\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    img = test_transform(img)\n",
        "    img = img.unsqueeze(0)\n",
        "    output = model(img)\n",
        "    prob = output.item()\n",
        "    results.append([img_path, prob])\n",
        "\n",
        "# write results to csv\n",
        "results_df = pd.DataFrame(results, columns=['path', 'prediction_score'])\n",
        "results_df.to_csv('team_1.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
