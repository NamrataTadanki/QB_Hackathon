{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ef_zFbk_cnBv"
      },
      "source": [
        "# **DATALOADING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NVD9bILs9TGA"
      },
      "outputs": [],
      "source": [
        "#####################################################\n",
        "################## PACKAGES #########################\n",
        "#####################################################\n",
        "import pandas as pd\n",
        "import sys \n",
        "import base64\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from datetime import datetime, timedelta, date\n",
        "from itertools import combinations\n",
        "from numpy.linalg import norm\n",
        "import pickle\n",
        "import os\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "import altair as alt\n",
        "from altair import expr, datum\n",
        "from vega_datasets import data\n",
        "from geopy.geocoders import Nominatim\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import PIL\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "import torch.optim as optim\n",
        "\n",
        "from utils import *\n",
        "tqdm.pandas()\n",
        "DATA_PATH = './data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNcKVv3N-DEK",
        "outputId": "0958e7ec-7160-4657-9445-680fbe7d26f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split completed successfully.\n"
          ]
        }
      ],
      "source": [
        "split_total_images_folder(DATA_PATH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bGppIF9CcsYi"
      },
      "source": [
        "# **DATA AUGMENTATION-PREPROCESS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jIPe8Scsvy2J"
      },
      "outputs": [],
      "source": [
        "# Set the paths to the training and validation data\n",
        "train_data_dir = './data/train_images'\n",
        "valid_data_dir = './data/val_images'\n",
        "\n",
        "# Set the image size, batch size\n",
        "img_size = (64, 64)\n",
        "batch_size = 32\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(size=img_size, padding=2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_data_dir,transform=train_transform)\n",
        "valid_dataset = datasets.ImageFolder(valid_data_dir,transform=valid_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tDt5mqakd28V"
      },
      "source": [
        "# **CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the CNN model architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(128 * (img_size[0] // 8) * (img_size[1] // 8), 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.pool3(x)\n",
        "        x = x.view(-1, 128 * (img_size[0] // 8) * (img_size[1] // 8))\n",
        "        x = self.fc1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jJXldThd9xX",
        "outputId": "bb769f65-c91d-4da9-8c65-5115f25e8bca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=8192, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize the model\n",
        "model = CNN()\n",
        "epochs= 5\n",
        "\n",
        "# Define the loss function, optimizer, and device\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Training Loss: 0.7050 - Validation Loss: 0.6934 - Training AUC: 0.4760 - Validation AUC: 0.6977\n",
            "Epoch 2 - Training Loss: 0.6936 - Validation Loss: 0.6895 - Training AUC: 0.5109 - Validation AUC: 0.7382\n",
            "Epoch 3 - Training Loss: 0.6871 - Validation Loss: 0.6816 - Training AUC: 0.5957 - Validation AUC: 0.7615\n",
            "Epoch 4 - Training Loss: 0.6880 - Validation Loss: 0.6871 - Training AUC: 0.5988 - Validation AUC: 0.6652\n",
            "Epoch 5 - Training Loss: 0.6697 - Validation Loss: 0.6653 - Training AUC: 0.6692 - Validation AUC: 0.6571\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    model.train()  # Set the model to training mode\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.float().unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        predicted = outputs\n",
        "        correct += (predicted == labels.float().unsqueeze(1)).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        predictions.extend(predicted.detach().cpu().numpy().flatten())\n",
        "        targets.extend(labels.detach().cpu().numpy().flatten())\n",
        "\n",
        "    # Calculate training accuracy and AUC\n",
        "    train_acc = correct / total\n",
        "    train_auc = roc_auc_score(targets, predictions)\n",
        "\n",
        "    # Validate the model\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "    valid_acc = 0.0\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in valid_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels.float().unsqueeze(1))\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            preds = outputs\n",
        "            valid_acc += torch.sum(preds == labels.float().unsqueeze(1))\n",
        "\n",
        "            predictions.extend(preds.detach().cpu().numpy().flatten())\n",
        "            targets.extend(labels.detach().cpu().numpy().flatten())\n",
        "\n",
        "    # Calculate validation AUC\n",
        "    valid_auc = roc_auc_score(targets, predictions)\n",
        "    \n",
        "    # Print the loss, accuracy, and AUC for each epoch\n",
        "    print(f'Epoch {epoch+1} - Training Loss: {running_loss/len(train_loader):.4f} - Validation Loss: {valid_loss/len(valid_loader):.4f} - Training AUC: {train_auc:.4f} - Validation AUC: {valid_auc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_df = pd.DataFrame({'prediction_score': predictions})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "predictions_df.to_csv('predictions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
